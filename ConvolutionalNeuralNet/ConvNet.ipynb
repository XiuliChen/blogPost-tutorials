{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = pd.read_csv(\"mnist-data/digits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10,28,28,3)\n",
    "w = np.random.randn(3,3,3,16)\n",
    "b = np.random.randn(1,1,1,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(x,mode=\"max\"):\n",
    "    #m*n_c*w*h\n",
    "    x_patches = x.reshape(x.shape[0],x.shape[1]//2, 2,x.shape[2]//2, 2,x.shape[3])\n",
    "    if mode==\"max\":\n",
    "        out = x_patches.max(axis=2).max(axis=3)\n",
    "        mask  =np.isclose(x,np.repeat(np.repeat(out,2,axis=1),2,axis=2)).astype(int)\n",
    "    elif mode==\"average\": \n",
    "        out =  x_patches.mean(axis=3).mean(axis=4)\n",
    "        mask = np.ones_like(x)*0.25\n",
    "    return out,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_backward(dx, mask):\n",
    "    return mask*(np.repeat(np.repeat(dx,2,axis=1),2,axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x, deriv=False):\n",
    "    if deriv:\n",
    "        return (x>0).astype(int)\n",
    "    return np.multiply(x, x>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(x,w,b,padding=\"same\"):\n",
    "    if padding==\"same\": \n",
    "        pad = (w.shape[0]-1)//2\n",
    "    else: #padding is valid - i.e no zero padding\n",
    "        pad =0 \n",
    "    n = (x.shape[1]-w.shape[0]+2*pad) +1 #ouput width/height\n",
    "    y = np.zeros((x.shape[0],n,n,w.shape[3]))\n",
    "    x = np.pad(x,((0,0),(pad,pad),(pad,pad),(0,0)),'constant', constant_values = 0)\n",
    "    w = np.flip(w,0)\n",
    "    w = np.flip(w,1)\n",
    "    \n",
    "    f = w.shape[0]\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        for k in range(w.shape[3]):\n",
    "            for d in range(x.shape[3]):\n",
    "                y[i,:,:,k]+=ndimage.convolve(x[i,:,:,d],w[:,:,d,k])[f//2:-(f//2),f//2:-(f//2)]\n",
    "                #ndimage.convolve starts convolution from centre of kernel and zero pads but we don't want this\n",
    "                #since we want to manually decide if we want to pad or not\n",
    "    y = y + b\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_forward(x,w,b):\n",
    "    return relu(w.dot(x)+b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_backward(dA,z,x,w,b):\n",
    "    m = dA.shape[1]\n",
    "    dZ = dA*relu(z, deriv = True)\n",
    "    dW = (1/m)*dZ.dot(x.T)\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dx =  np.dot(w.T,dZ)\n",
    "    return dx, dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_forward(x,w,b):\n",
    "    z = w.dot(x)+b\n",
    "    return np.exp(z)/np.sum(np.exp(z),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_backward(y_hat, y, w, b, x):\n",
    "    dZ = y_hat - y\n",
    "    dW = (1/m)*dZ.dot(x.T)\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n",
    "    dx =  np.dot(w.T,dZ)\n",
    "    return dx, dW,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dZ,x,w,padding=\"same\"):\n",
    "    \n",
    "    db = np.sum(dZ, axis=(0,1,2), keepdims=True)\n",
    "    \n",
    "    if padding==\"same\": \n",
    "        pad = (w.shape[0]-1)//2\n",
    "    else: #padding is valid - i.e no zero padding\n",
    "        pad =0 \n",
    "    x_padded = np.pad(x,((0,0),(pad,pad),(pad,pad),(0,0)),'constant', constant_values = 0)\n",
    "    \n",
    "    #this will allow us to broadcast operation\n",
    "    x_padded_bcast = np.expand_dims(x_padded, axis=-1) \n",
    "    dZ_bcast = np.expand_dims(dZ, axis=-2)\n",
    "    \n",
    "    dW = np.zeros_like(w)\n",
    "    f=w.shape[0]\n",
    "    w_x = x_padded.shape[1]\n",
    "    for i in range(f):\n",
    "        for j in range(f):\n",
    "            dW[i,j,:,:] = np.sum(dZ_bcast*x_padded_bcast[:,i:w_x-(f-1 -i),j:w_x-(f-1 -j),:,:],axis=(0,1,2))  \n",
    "    \n",
    "    dx = np.zeros_like(x_padded)\n",
    "    Z_pad = f-1\n",
    "    dZ_padded = np.pad(dZ,((0,0),(Z_pad,Z_pad),(Z_pad,Z_pad),(0,0)),'constant', constant_values = 0)  \n",
    "    for i in range(x.shape[0]):\n",
    "        for k in range(w.shape[3]):\n",
    "            for d in range(x.shape[3]):\n",
    "                dx[i,:,:,d]+=ndimage.convolve(dZ_padded[i,:,:,k],w[:,:,d,k])[f//2:-(f//2),f//2:-(f//2)]\n",
    "    dx = dx[:,pad:dx.shape[1]-pad,pad:dx.shape[2]-pad,:]\n",
    "    return dx,dW,db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to define the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_conv_parameters(f, n_c, k):\n",
    "    return np.random.rand(f,f,n_c,k), np.random.rand(1,1,1,k)\n",
    "def init_fc_parameters(n_x,n_y):\n",
    "    return np.random.rand(n_y,n_x),np.random.rand(n_y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_parameters():    \n",
    "    parameters={}\n",
    "    parameters[\"W_conv1\"], parameters[\"b_conv1\"] = init_conv_parameters(5, 1, 32)\n",
    "    parameters[\"W_conv2\"], parameters[\"b_conv2\"] = init_conv_parameters(3, 32, 32)\n",
    "\n",
    "    parameters[\"W_conv3\"], parameters[\"b_conv3\"] = init_conv_parameters(3, 32, 64)\n",
    "    parameters[\"W_conv4\"], parameters[\"b_conv4\"] = init_conv_parameters(3, 64,64)\n",
    "\n",
    "    parameters[\"W_fc1\"],parameters[\"b_fc1\"] = init_fc_parameters(3136,512)\n",
    "    parameters[\"W_softmax\"],parameters[\"b_softmax\"] = init_fc_parameters(512,10)\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    \n",
    "    cache={}\n",
    "    \n",
    "    cache[\"z_conv1\"] = conv_forward(X,parameters[\"W_conv1\"], parameters[\"b_conv1\"])\n",
    "    cache[\"a_conv1\"] = relu(cache[\"z_conv1\"])\n",
    "    \n",
    "    cache[\"z_conv2\"] = conv_forward(cache[\"a_conv1\"],parameters[\"W_conv2\"], parameters[\"b_conv2\"])\n",
    "    cache[\"a_conv2\"] = relu(cache[\"z_conv2\"])\n",
    "    \n",
    "    cache[\"z_pool1\"], cache[\"mask_pool1\"] = pool_forward(cache[\"a_conv2\"])\n",
    "    \n",
    "    cache[\"z_conv3\"] = conv_forward(cache[\"z_pool1\"],parameters[\"W_conv3\"], parameters[\"b_conv3\"])\n",
    "    cache[\"a_conv3\"] = relu(cache[\"z_conv3\"])\n",
    "    \n",
    "    cache[\"z_conv4\"] = conv_forward(cache[\"a_conv3\"],parameters[\"W_conv4\"], parameters[\"b_conv4\"] )\n",
    "    cache[\"a_conv4\"] = relu(cache[\"z_conv4\"])\n",
    "    \n",
    "    cache[\"z_pool2\"], cache[\"mask_pool2\"] = pool_forward(cache[\"a_conv4\"])\n",
    "    \n",
    "    cache[\"a_flatten\"] = np.reshape(cache[\"z_pool2\"], (a.shape[0],-1))\n",
    "    cache[\"a_fc1\"] = fc_forward( cache[\"a_flatten\"],parameters[\"W_fc1\"],parameters[\"b_fc1\"])\n",
    "    \n",
    "    return softmax(cache[\"a_fc1\"],parameters[\"W_softmax\"],parameters[\"b_softmax\"]),cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(X,Y,Y_pred,parameters,cache,lambd):\n",
    "    grads = {}\n",
    "    \n",
    "    dA, grads[\"dW_softmax\"],grads[\"db_softmax\"] =softmax_backward(Y_pred, Y, parameters[\"W_softmax\"],parameters[\"b_softmax\"],cache[\"a_fc1\"])\n",
    "    dx, dW,db\n",
    "    dA, grads[\"dW_fc1\"],grads[\"db_fc1\"] = fc_backward(dA,cache[\"a_fc1\"],cache[\"a_flatten\"],parameters[\"W_fc1\"],parameters[\"b_fc1\"])\n",
    "    \n",
    "    dA = np.reshape(dA,cache[\"z_pool2\"].shape)\n",
    "    dA = pool_backward(dA, cache[\"mask_pool2\"])\n",
    "    \n",
    "    dA = relu(dA,deriv=True)\n",
    "    dA, grads[\"dW_conv4\"],grads[\"db_conv4\"] = conv_backward(dA,cache[\"a_conv3\"],parameters[\"W_conv4\"])\n",
    "    \n",
    "    dA = relu(dA,deriv=True)\n",
    "    dA, grads[\"dW_conv3\"],grads[\"db_conv3\"] = conv_backward(dA,cache[\"z_pool1\"],parameters[\"W_conv3\"])\n",
    "    \n",
    "    dA = pool_backward(dA, cache[\"mask_pool1\"])\n",
    "    \n",
    "    dA = relu(dA,deriv=True)\n",
    "    dA, grads[\"dW_conv2\"],grads[\"db_conv2\"] = conv_backward(dA,cache[\"a_conv1\"],parameters[\"W_conv2\"])\n",
    "    \n",
    "    dA = relu(dA,deriv=True)\n",
    "    _, grads[\"dW_conv1\"],grads[\"db_conv1\"] = conv_backward(dA,X,parameters[\"W_conv1\"])\n",
    "    \n",
    "    #regularisation term\n",
    "    for key in grads:\n",
    "        if \"W\" in key:\n",
    "            grads[key]+= (lambd/X.shape[0])*parameters[key[1:]] \n",
    "    return grads        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_pred,y,parameters,lambd):\n",
    "    cost = 0\n",
    "    m = y.shape[1]\n",
    "    L = len(parameters)//2\n",
    "    cost += (-1/m)*np.sum(y*np.log(y_pred))\n",
    "    \n",
    "    regularisation_term = 0\n",
    "    for key in parameters:\n",
    "        if \"W\" in key:\n",
    "            regularisation_term += np.sum(np.square(parameters[key]))\n",
    "    \n",
    "    regularised_cost = cost + (lambd/(2*m))*regularisation_term\n",
    "    \n",
    "    return regularised_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y):\n",
    "    preds = np.argmax(y_pred,axis=0)\n",
    "    truth = np.argmax(y,axis=0)\n",
    "    return np.mean(np.equal(preds,truth).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, Y_train, X_dev, Y_dev,num_epochs,batch_size,lambd,learning_rate):\n",
    "    train_costs = []\n",
    "    dev_evals = []\n",
    "    \n",
    "    parameters = initialise_parameters()\n",
    "    for epoch in range (num_epochs):\n",
    "        print(\"Training the model, epoch: \" + str(epoch+1))\n",
    "        #cycle through the entire training set in batches\n",
    "        for i in range(0,X_train.shape[1]//batch_size):\n",
    "            \n",
    "            #get the next minibatch to train on\n",
    "            X_train_minibatch = X_train[:,i*batch_size:(i+1)*batch_size]\n",
    "            Y_train_minibatch = Y_train[:,i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "            #perform one cycle of forward and backward propagation to get the partial derivatives w.r.t. the weights\n",
    "            #and biases. Calculate the cost - used to monitor training\n",
    "            y_pred, cache = forward_prop(X_train_minibatch,parameters)\n",
    "            minibatch_cost = loss_function(y_pred,Y_train_minibatch,parameters,lambd)\n",
    "            minibatch_grads = backprop(X_train_minibatch,Y_train_minibatch,y_pred,parameters, cache,lambd)\n",
    "            \n",
    "            #update the parameters using gradient descent\n",
    "            for param in params.keys:\n",
    "                params[param] = params[param] - learning_rate*grads[\"d\"+param]\n",
    "        \n",
    "            #periodically output an update on the current cost and performance on the dev set for visualisation\n",
    "            if(i*(epoch+1)%1 == 0):\n",
    "                train_costs.append(minibatch_cost)\n",
    "                print(\"Cost after iteration \" + str(i*(epoch+1)) + \": \" + str(minibatch_cost))\n",
    "                y_dev_pred,_ = forward_propagation(X_dev,parameters)\n",
    "                dev_eval_metric = accuracy(y_dev_pred,Y_dev)\n",
    "                dev_evals.append(dev_eval_metric)\n",
    "                print(\"Accuracy on dev set: \"+ str(dev_eval_metric))\n",
    "    print(\"Training complete!\")\n",
    "    #return the trained parameters and the visualisation metrics\n",
    "    return parameters, train_costs, dev_evals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(train_costs, dev_evals, parameters,X_train, Y_train, X_dev, Y_dev, X_test, Y_test):\n",
    "    #plot the graphs of training set error and dev set F1 score\n",
    "    plt.plot(np.squeeze(train_costs))\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('1000s of Iterations')\n",
    "    plt.title(\"Training Set Error\")\n",
    "    plt.show()\n",
    "    plt.plot(np.squeeze(dev_evals))\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.xlabel('1000s of Iterations')\n",
    "    plt.title(\"Dev Set Accuracy\")\n",
    "    plt.show()\n",
    "        \n",
    "    #For each of the train, dev and test sets, perform a step of forward propagation to obtain the trained model's \n",
    "    #predictions and evaluate this with an F1 score.\n",
    "    y_pred_train,_ = forward_propagation(X_train,parameters)\n",
    "    print(\"The train set accuracy is: \"+str(accuracy(y_pred_train,Y_train)))\n",
    "    \n",
    "    y_pred_dev,_ = forward_propagation(X_dev,parameters)\n",
    "    print(\"The dev set accuracy is: \"+str(accuracy(y_pred_dev,Y_dev)))\n",
    "    \n",
    "    y_pred_test,_= forward_propagation(X_test,parameters)\n",
    "    print(\"The test set F1 score is: \"+str(accuracy(y_pred_test,Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(TrainTestDevSets, hyperparameters):\n",
    "    \n",
    "    X_train = TrainTestDevSets[\"X_train\"] \n",
    "    Y_train = TrainTestDevSets[\"Y_train\"]\n",
    "\n",
    "    X_dev = TrainTestDevSets[\"X_dev\"]\n",
    "    Y_dev = TrainTestDevSets[\"Y_dev\"] \n",
    "    \n",
    "    X_test = TrainTestDevSets[\"X_test\"] \n",
    "    Y_test = TrainTestDevSets[\"Y_test\"]\n",
    "    \n",
    "    num_epochs = hyperparameters[\"num_epochs\"]\n",
    "    batch_size = hyperparameters[\"batch_size\"]\n",
    "    lambd = hyperparameters[\"lambd\"]\n",
    "    learning_rate = hyperparameters[\"learning_rate\"]\n",
    "    \n",
    "    parameters, train_costs, dev_evals = train_model(X_train, Y_train, X_dev, Y_dev,num_epochs,batch_size,lambd,learning_rate)         \n",
    "    evaluate_model(train_costs, dev_evals, parameters,X_train, Y_train, X_dev, Y_dev, X_test, Y_test)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = mnist_data.reindex(np.random.permutation(mnist_data.index)) #shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 42000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = mnist_data.loc[:,mnist_data.columns!=\"label\"].as_matrix()\n",
    "X = np.reshape(X,(X.shape[0], 28,28,1))\n",
    "Y = mnist_data.loc[:,[\"label\"]].as_matrix()\n",
    "Y = np.eye(10)[Y.reshape(-1)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTestDevSets={}\n",
    "TrainTestDevSets[\"X_train\"] = X[:28000]\n",
    "TrainTestDevSets[\"Y_train\"] = Y[:,:28000]\n",
    "TrainTestDevSets[\"X_dev\"] = X[28000:35000]\n",
    "TrainTestDevSets[\"Y_dev\"] =Y[:,28000:35000]\n",
    "TrainTestDevSets[\"X_test\"] = X[35000:]\n",
    "TrainTestDevSets[\"Y_test\"] = Y[:,35000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={}\n",
    "hyperparameters[\"num_epochs\"] = 10 #number of passes through the training set\n",
    "hyperparameters[\"batch_size\"] = 128 #number of examples trained upon in each step of training\n",
    "hyperparameters[\"lambd\"] = 1 #regularisation parameter \n",
    "hyperparameters[\"learning_rate\"] = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model, epoch: 1\n",
      "Training the model, epoch: 2\n",
      "Training the model, epoch: 3\n",
      "Training the model, epoch: 4\n",
      "Training the model, epoch: 5\n",
      "Training the model, epoch: 6\n",
      "Training the model, epoch: 7\n",
      "Training the model, epoch: 8\n",
      "Training the model, epoch: 9\n",
      "Training the model, epoch: 10\n",
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10972bf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e769320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = run_model(TrainTestDevSets, hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
